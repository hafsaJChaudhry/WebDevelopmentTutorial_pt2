{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "3TbCLGCN6oUG"
      ],
      "authorship_tag": "ABX9TyMNnEv0DD0zwBeSSLJ1uumS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hafsaJChaudhry/WebDevelopmentTutorial_pt2/blob/main/WebDevelopmentWPython_p2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Step by Step Tutorial for Creating Dynamic Database-Driven Web Apps with Python Flask, MySQL**\n",
        "\n",
        "##**This tutorial will be in parts, current notebook is part 2**\n",
        "Will show how to build and deploy a site using the Flask Python web framework.\n",
        "\n",
        "Then we will show how to connect the Flask application to a cloud MySQL database. To deploy a production-ready, database-driven web application.\n",
        "\n",
        "***I am only storing my steps on google collab!! I wrote and tested my code on VSC***"
      ],
      "metadata": {
        "id": "guF8jyuyjpzf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**2.1: Setting up our own domain**\n",
        "Right now our website is accessible through http://127.0.0.1:5000 on our virtual environment, but let's set up our own unique custom domain \"hafsacareers.com\" by deploying our github repository to Render and then configuring our registering on domains.google.com"
      ],
      "metadata": {
        "id": "i3CHKWutjxmu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Github Repository Steps\n"
      ],
      "metadata": {
        "id": "3TbCLGCN6oUG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we will save all our previous work (to create a flask web application) on a github repository. Then we will create a new repository on github called pt2, and we will skip making a \"readme\" file. This will prompt us to directions on how to copy/fork files from other public repositories (yours or from the world wide community). Easiest method: last option to copy-paste URL of 1st repository that you wish to copy."
      ],
      "metadata": {
        "id": "raszVPsjGNc0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Render.com : Register Custom Domain - TBD STEP\n"
      ],
      "metadata": {
        "id": "UPUUCd9W9ZDq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Register a free render account with your github account.\n",
        "2. On the dashboard page, press the + icon and select \"web service\" from the downbar.\n",
        "3. Then \"configure from github\" and select the repository you want to grant access too.\n",
        "4. Will redirect you to new web service page. Press \"connect\" to your repository.\n",
        "5. Give it a name, and everything else should be standard up until start command. Then write gunicorn app:app  (gunicorn is to run flask application in production. then our flask python file is app.py)\n",
        "\n",
        "Now it will take the code from the repository and build+deploy it that will be visible with the URL it renders: https://hafsa-career.onrender.com\n",
        "\n",
        "But we want to put it on a **custom domain**:\n",
        "1. Click on settings from the sidebar\n",
        "2. Scroll down to \"custom domain\" and press the \"add\" button\n",
        "3. write \"hafsacareers.com\"\n",
        "4. will give you url link and DNS directions, move to next step.\n",
        "\n",
        "Now we need to **register our domain**:\n",
        "1. Go to domains.google.com\n",
        "2. ..."
      ],
      "metadata": {
        "id": "xCkhGSUYGKTR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up Cloud AWS-MySQL Database to Connect to WorkBench"
      ],
      "metadata": {
        "id": "rzYhGFpnG1yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Go to planetscale.com and create/login to an account\n",
        "2. Press create a database\n",
        "3. name it, press hobby version so its free\n",
        "4. store one-time database .env credentials:\n",
        "\n",
        "\n",
        "    DATABASE_HOST=aws.connect.psdb.cloud\n",
        "    \n",
        "    DATABASE_NAME=insert database name\n",
        "    \n",
        "    DATABASE_USERNAME=insert username\n",
        "    \n",
        "    DATABASE_PASSWORD=insert database password\n",
        "5. open up mysql workbench, press + and add in new log in credentials from above to connect to cloud aws database (give it a connection name, port is automatically configured, put in rest of info, click on password button to put in password, and then for default scheme add in the DATABASE_NAME from above)\n",
        "6. test connection then press okay and open workbench\n",
        "\n",
        "# Directions to connection our AWS-MySQL Database via python (provided also by planetscale.com):\n",
        "1. terminal:\n",
        "    \n",
        "    \n",
        "    pip install python-dotenv mysqlclient\n",
        "\n",
        "2. .env (same credentials as above)\n",
        "3. main.py\n",
        "    \n",
        "    \n",
        "    from dotenv import load_dotenv\n",
        "    load_dotenv()\n",
        "    import os\n",
        "    import MySQLdb\n",
        "\n",
        "    connection = MySQLdb.connect(\n",
        "      host= os.getenv(\"DB_HOST\"),\n",
        "      user=os.getenv(\"DB_USERNAME\"),\n",
        "      passwd= os.getenv(\"DB_PASSWORD\"),\n",
        "      db= os.getenv(\"DB_NAME\"),\n",
        "      autocommit = True,\n",
        "      ssl_mode = \"VERIFY_IDENTITY\",\n",
        "      ssl      = {\n",
        "        \"ca\": \"/etc/ssl/cert.pem\"\n",
        "      }\n",
        "    )\n",
        "  \n"
      ],
      "metadata": {
        "id": "gkt7B3dzHDLg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Workbench commands"
      ],
      "metadata": {
        "id": "v-ietRMzKaBY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "    SHOW DATABASES;\n",
        "  press lightning bolt and itll show you what your current database looks like:\n",
        "  >hafsacareers, information_schema, mysql, sys, performance schema\n",
        "\n",
        "Lets **see whats inside this database**:\n",
        "    \n",
        "    USE hafsacareers;\n",
        "  press lightning bolt to be in hafsacareer directory\n",
        "    \n",
        "    SHOW TABLES;\n",
        "  will show no current tables in database\n",
        "  information in databases are organized in tables. Each table can represent 1 entity. Think of it as a sheet in a spreadsheet workbook.\n",
        "\n",
        "    CREATE TABLE jobs (\n",
        "      id INT NOT NULL AUTO_INCREMENT, #new id will be automatically generated\n",
        "      title VARCHAR(250) NOT NULL,\n",
        "      location VARCHAR(250) NOT NULL,\n",
        "      salary INT,\n",
        "      currency VARCHAR(10),\n",
        "      responsibilities VARCHAR(2000),\n",
        "      requirements VARCHAR(2000),\n",
        "      PRIMARY KEY (id) #telling sequel every id will be unique, every row will have unique id, and you can get data out of the table by providing specific id (\"give me info for job w/ id ..\")\n",
        "    );\n",
        "  run and check on schemas\n",
        "\n",
        "  >you can open a new tab on WorkBench py pressing command+t\n",
        "\n",
        "Lets see whats **inside our jobs table**:\n",
        "    \n",
        "    SELECT * FROM jobs;\n",
        "  will pull up a table that shows NULL since we dont have data yet\n",
        "\n",
        "  >you can also just go on schemas tab, open till jobs tab and press table icon\n",
        "\n",
        "\n",
        "Now lets **add in data** to our tables:\n",
        "\n",
        ">first way:\n",
        "\n",
        "looking at our create table jobs() we only need 3 vitale data: id, title and location:\n",
        "\n",
        "    INSERT INTO jobs (title, location)\n",
        "    VALUES ('Data Analyst', 'NYC, New York');\n",
        "  check in schemas table\n",
        "\n",
        ">second way:\n",
        "\n",
        "workbench lets you type right into the table in a user friendly interface. just start typing where it says null. then press \"apply\" under the tab\n",
        "\n",
        "add in all the info including job responsibilites and requirements\n",
        "\n",
        "  \n"
      ],
      "metadata": {
        "id": "-EJWU7f3Kg1j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Connect Database to your python files using SQL Alchemy**"
      ],
      "metadata": {
        "id": "Ti8Pfy7wUO4_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "    pip install sqlalchemy\n",
        "    pip install pymysql\n",
        "    pip install python-dotenv mysqlclient\n",
        "for some reason VSC did not like this so I switched to online Replit and connected my github to continue...will finish the project and create working files and then try to configure my bin folder to find the sqlalchemy library"
      ],
      "metadata": {
        "id": "17-ZE4nGUVhq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#create a database.py and engine"
      ],
      "metadata": {
        "id": "Qv7hB1p9fjY7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create an engine by following this syntax and adding in our info we collected when we set up our cloud AWS MySQL sever inside the <>\n",
        "    \n",
        "    engine = create_engine(\"mysql+pymysql://<username>:<password>@<host>/<dbname>?charset=utf8mb4')\n",
        "\n",
        "  then: run python database.py"
      ],
      "metadata": {
        "id": "iFpOsbxPfkla"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sqlalchemy import create_engine\n",
        "\n",
        "engine = create_engine(\"mysql+pymysql://<username>:<password>@<host>/<dbname>?charset=utf8mb4\")"
      ],
      "metadata": {
        "id": "-quMNc-QfM_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Get information out of the engine"
      ],
      "metadata": {
        "id": "dHYGgA4fgOX4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "by making a connection to the database by the engine,\n",
        "\n",
        "import create_engine,text\n",
        "\n",
        "and we will use the python requirements from AWS with connect_args, since I got an error (http vs https will sometimes make it complicated for security reason)"
      ],
      "metadata": {
        "id": "qHX1WJPlgbe5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sqlalchemy import create_engine, text\n",
        "\n",
        "db_connection = \"mysql+pymysql://<username>:<password>@<host>/<dbname>?charset=utf8mb4\"\n",
        "\n",
        "#connect to our mysql database\n",
        "engine = create_engine(db_connection,\n",
        "                      connect_args={\n",
        "                        \"ssl\": {\n",
        "                          \"ssl_ca\": \"/etc/ssl/cert.pem\"\n",
        "                        }\n",
        "                      })\n",
        "\n",
        "\n",
        "with engine.connect() as conn:\n",
        "  #get all data from our jobs table in our database\n",
        "  result = conn.execute(text(\"SELECT * FROM jobs\"))\n",
        "  print(result.all())"
      ],
      "metadata": {
        "id": "uyYX1r8HlPeh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "will return full database in terminal output:\n",
        "\n",
        "[(1, 'Data Analyst', 'NYC, New York', 200000, 'USD', ' \\n \\n \\t\\nProcess data using Python, SQL and other tools through the analytics data pipeline\\nIdentify and translate business rules into specificati ... (4 characters truncated) ... and documentation\\nEnsure quality control and follow peer review guidelines\\nAdhere to best practices and standards, maintaining process efficiencies', \" \\n \\n \\t\\nBachelor's degree (required) or above in Computer Science, Mathematics, Economics, or experience in related analytical field\\nExcellent an ... (53 characters truncated) ...  Python and SQL programming experience\\nBasic skills in MS Excel\\nKnowledge of cloud computing platforms (AWS, GCP) and knowledge of Spark is desired\"), (2, 'Data Scientist', 'Tysons, Virginia', 150000, 'USD ', ' \\n \\t\\nDraft detailed scope for assigned projects, addressing suggested methodology and execution framework.\\nExecute on the plan with appropriate d ... (136 characters truncated) ...  Scientists, Data Engineers and self.\\nAccountable for the quality of the end solution or model by planning the required reviews on code and process.', ' \\n \\t\\nExpert knowledge in Deep Learning techniques and exploring newer approaches like federated learning and transfer learning.\\nProficient in som ... (167 characters truncated) ... lutionary Algorithms, Support Vector Machines.\\nProficient in advanced data mining and statistical modeling techniques, including Predictive modeling'), (3, 'Frontend Engineer', 'remote', 140000, 'USD', ' \\n \\t\\nTranslate designs and wireframes into high quality JS, CSS, HTML templates\\nDesign, build, and maintain high performance, reusable, and relia ... (472 characters truncated) ... mize for maximum speed and scalability\\nIdentify and correct bottlenecks and fix bugs.\\nHelp maintain code quality, organization, and automatization.', ' \\n \\t\\nStrong knowledge of programming skills in JS, CSS and HTML\\nFamiliarity with responsive and adaptive web design, and good knowledge of JS lib ... (63 characters truncated) ...  the JS frameworks (e.g. VueJS, Angular JS, NodeJS, ReactJS)\\nExperience with building websites, ability to handle cross browser compatibility issues'), (4, 'Backend Engineer', 'San Francisco, USA', 150000, 'USD', ' \\n \\t\\nDesign and develop a cloud based backend\\nParticipate and produce a scalable cloud based backend system\\nDesign and develop REST based APIs\\nInteract with customer directly and with other stakeholders in the organization', ' \\n \\t\\nHands on experience with building a web backend in Java or Golang\\nKnowledge of designing and building REST APIs\\nProven experience in buildi ... (26 characters truncated) ... t backend\\nGood understanding of database schemas and using both relational (SQL) and noSQL based data stores\\nStrong analytical and debugging skills')]"
      ],
      "metadata": {
        "id": "Hi04VAMqm8LA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "lets explore some more:"
      ],
      "metadata": {
        "id": "dKuvdhcAnGe4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#explore the data\n",
        "with engine.connect() as conn:\n",
        "  #get all data from our jobs table in our database\n",
        "  result = conn.execute(text(\"SELECT * FROM jobs\"))\n",
        "\n",
        "  #will return whole database in terminal output\n",
        "  print(result.all())\n",
        "\n",
        "  #wil show that the type is a cursor\n",
        "  print(type(result))\n",
        "\n",
        "  #will return a list\n",
        "  result_all = result.all()\n",
        "  print(type(result_all))\n",
        "\n",
        "  #will return a legacy row\n",
        "  first_result = result_all[0]\n",
        "  print(type(first_result))"
      ],
      "metadata": {
        "id": "0dMcWbaknIW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#make rows into a list of dictionaries\n",
        "so that it can have the column names per result. example: id:1"
      ],
      "metadata": {
        "id": "Da7jKvCEnOzy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  with engine.connect() as conn:\n",
        "    result = conn.execute(text(\"select * from jobs\"))\n",
        "\n",
        "    # Fetch the column names from the result set\n",
        "    columns = result.keys()\n",
        "\n",
        "    # Create a list of dictionaries from the result set\n",
        "    jobs = [dict(zip(columns, row)) for row in result]\n",
        "\n",
        "    print(jobs)"
      ],
      "metadata": {
        "id": "XdFxqi2xnTOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "returns:\n",
        "\n",
        "[{'id': 1, 'title': 'Data Analyst', 'location': 'NYC, New York', 'salary': 200000, 'currency': 'USD', 'responsibilities': ' \\n \\n \\t\\nProcess data using Python, SQL and other tools through the analytics data pipeline\\nIdentify and translate business rules into specifications and documentation\\nEnsure quality control and follow peer review guidelines\\nAdhere to best practices and standards, maintaining process efficiencies', 'requirements': \" \\n \\n \\t\\nBachelor's degree (required) or above in Computer Science, Mathematics, Economics, or experience in related analytical field\\nExcellent analytic and creative problem-solving skills\\n1-3 years Python and SQL programming experience\\nBasic skills in MS Excel\\nKnowledge of cloud computing platforms (AWS, GCP) and knowledge of Spark is desired\"}, {'id': 2, 'title': 'Data Scientist', 'location': 'Tysons, Virginia', 'salary': 150000, 'currency': 'USD ', 'responsibilities': ' \\n \\t\\nDraft detailed scope for assigned projects, addressing suggested methodology and execution framework.\\nExecute on the plan with appropriate data mining, analytical and data science techniques.\\nPerform quality assurance of data and deliverables for work performed by other Data Scientists, Data Engineers and self.\\nAccountable for the quality of the end solution or model by planning the required reviews on code and process.', 'requirements': ' \\n \\t\\nExpert knowledge in Deep Learning techniques and exploring newer approaches like federated learning and transfer learning.\\nProficient in some or all of the following techniques: Linear & Logistic Regression, Decision Trees, Random Forests, K-Nearest Neighbors, Markov Chain, Monte Carlo, Gibbs Sampling, Evolutionary Algorithms, Support Vector Machines.\\nProficient in advanced data mining and statistical modeling techniques, including Predictive modeling'}, {'id': 3, 'title': 'Frontend Engineer', 'location': 'remote', 'salary': 140000, 'currency': 'USD', 'responsibilities': ' \\n \\t\\nTranslate designs and wireframes into high quality JS, CSS, HTML templates\\nDesign, build, and maintain high performance, reusable, and reliable UI components and products\\nEnsure the best possible performance, quality, and optimize for maximum speed and scalability\\nIdentify and correct bottlenecks and fix bugs.\\nHelp maintain code quality, organization, and automatization. \\n \\t\\nTranslate designs and wireframes into high quality JS, CSS, HTML templates\\nDesign, build, and maintain high performance, reusable, and reliable UI components and products\\nEnsure the best possible performance, quality, and optimize for maximum speed and scalability\\nIdentify and correct bottlenecks and fix bugs.\\nHelp maintain code quality, organization, and automatization.', 'requirements': ' \\n \\t\\nStrong knowledge of programming skills in JS, CSS and HTML\\nFamiliarity with responsive and adaptive web design, and good knowledge of JS libraries such as JQuery\\nStrong knowledge of about atleast one of the JS frameworks (e.g. VueJS, Angular JS, NodeJS, ReactJS)\\nExperience with building websites, ability to handle cross browser compatibility issues'}, {'id': 4, 'title': 'Backend Engineer', 'location': 'San Francisco, USA', 'salary': 150000, 'currency': 'USD', 'responsibilities': ' \\n \\t\\nDesign and develop a cloud based backend\\nParticipate and produce a scalable cloud based backend system\\nDesign and develop REST based APIs\\nInteract with customer directly and with other stakeholders in the organization', 'requirements': ' \\n \\t\\nHands on experience with building a web backend in Java or Golang\\nKnowledge of designing and building REST APIs\\nProven experience in building a scalable and resilient backend\\nGood understanding of database schemas and using both relational (SQL) and noSQL based data stores\\nStrong analytical and debugging skills'}]"
      ],
      "metadata": {
        "id": "k2CukKM72f7X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**lets now make this a function:**"
      ],
      "metadata": {
        "id": "Nu3CEiSr4PW-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sqlalchemy import create_engine, text\n",
        "\n",
        "db_connection = \"mysql+pymysql://<username>:<password>@<host>/<dbname>?charset=utf8mb4\"\n",
        "\n",
        "#connect to our mysql database\n",
        "engine = create_engine(db_connection,\n",
        "                      connect_args={\n",
        "                        \"ssl\": {\n",
        "                          \"ssl_ca\": \"/etc/ssl/cert.pem\"\n",
        "                        }\n",
        "                      })\n",
        "\n",
        "with engine.connect() as conn:\n",
        "  result = conn.execute(text(\"SELECT * FROM jobs\"))\n",
        "\n",
        "\n",
        "def load_jobs_from_db():\n",
        "  with engine.connect() as conn:\n",
        "    result = conn.execute(text(\"select * from jobs\"))\n",
        "\n",
        "    # Fetch the column names from the result set\n",
        "    columns = result.keys()\n",
        "\n",
        "    # Create a list of dictionaries from the result set\n",
        "    jobs = [dict(zip(columns, row)) for row in result]\n",
        "\n",
        "    return jobs"
      ],
      "metadata": {
        "id": "5U9Snis_4R6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Display Data in your Web App**\n",
        "before our data had hardcoded data. now we will get rid of the hardcode and display from our database - **major change in code**"
      ],
      "metadata": {
        "id": "wxMBpWhG2oNC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#app.py\n",
        "from flask import Flask, render_template, jsonify, request\n",
        "from database import load_jobs_from_db\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route(\"/\")\n",
        "def hello_hafsa():\n",
        "  jobs = load_jobs_from_db()\n",
        "  return render_template('home.html',\n",
        "                           jobs=jobs)\n",
        "\n",
        "#RestAPI\n",
        "@app.route(\"/api/jobs\")\n",
        "def list_jobs():\n",
        "  return jsonify(JOBS)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  app.run(host='0.0.0.0', debug=True)\n"
      ],
      "metadata": {
        "id": "1mMMnDkp3497"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Add Data to your Database/Table**"
      ],
      "metadata": {
        "id": "HiYtdzCaAG-U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#database.py\n",
        "#Adding data into our table\n",
        "def add_application_to_db(job_id, data):\n",
        "  with engine.connect() as conn:\n",
        "    #have form request variables\n",
        "    query = text(f\"INSERT INTO applications (job_id, full_name, email, linkedin_url, education, work_experience, resume_url) VALUES ({job_id}, '{data['full_name']}', '{data['email']}', '{data['linkedin_url']}', '{data['education']}', '{data['work_experience']}', '{data['resume_url']}')\")\n",
        "\n",
        "    conn.execute(query)\n"
      ],
      "metadata": {
        "id": "2vKWiNIzAMvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#app.py\n",
        "#@app.route(\"/job/<int:id>/apply\", methods=['GET', 'POST'])\n",
        "@app.route(\"/job/<int:id>/apply\", methods=['post'])\n",
        "def apply_to_job(id):\n",
        "  #get data from the form\n",
        "  data = request.form\n",
        "  #get job id (for HTML so we can print out job title)\n",
        "  job = load_job_from_db(id)\n",
        "\n",
        "  #add data to database\n",
        "  add_application_to_db(id, data)\n",
        "\n",
        "  #return html page that says application was successfully submitted\n",
        "  return render_template('application_submitted.html', application=data, role=job)"
      ],
      "metadata": {
        "id": "uLvnGjzTAag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**YOU DID IT!! Thats pretty much it!!**\n",
        "**These steps from part1 and part2 look long but are practically repeating in every application you will create and run.**"
      ],
      "metadata": {
        "id": "aqhuHvO45H12"
      }
    }
  ]
}